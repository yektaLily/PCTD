{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T08:16:15.458522Z",
     "iopub.status.busy": "2022-07-22T08:16:15.458138Z",
     "iopub.status.idle": "2022-07-22T08:16:24.567400Z",
     "shell.execute_reply": "2022-07-22T08:16:24.566204Z",
     "shell.execute_reply.started": "2022-07-22T08:16:15.458491Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install torchtext==0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T08:58:31.588850Z",
     "iopub.status.busy": "2022-07-22T08:58:31.588404Z",
     "iopub.status.idle": "2022-07-22T08:58:31.595656Z",
     "shell.execute_reply": "2022-07-22T08:58:31.594021Z",
     "shell.execute_reply.started": "2022-07-22T08:58:31.588813Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "from torchtext import data, datasets\n",
    "import spacy\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.metrics import recall_score,precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T08:16:24.581002Z",
     "iopub.status.busy": "2022-07-22T08:16:24.580598Z",
     "iopub.status.idle": "2022-07-22T08:16:24.597207Z",
     "shell.execute_reply": "2022-07-22T08:16:24.596354Z",
     "shell.execute_reply.started": "2022-07-22T08:16:24.580970Z"
    }
   },
   "outputs": [],
   "source": [
    "import re, string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "def preprocess(text):\n",
    "    text = text.lower() \n",
    "    text=text.strip()\n",
    "    text=re.compile('<.*?>').sub('', text)\n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = re.sub(r'\\[[0-9]*\\]',' ',text)\n",
    "    text=re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "    text = re.sub(r'\\d',' ',text) \n",
    "    text = re.sub(r'\\s+',' ',text)\n",
    "    return text\n",
    "# STOPWORD REMOVAL\n",
    "def stopword(string):\n",
    "    a= [i for i in string.split() if i not in stopwords.words('english')]\n",
    "    return ' '.join(a)\n",
    "#LEMMATIZATION\n",
    "# Initialize the lemmatizer\n",
    "wl = WordNetLemmatizer()\n",
    "\n",
    "# This is a helper function to map NTLK position tags\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "# Tokenize the sentence\n",
    "def lemmatizer(string):\n",
    "    word_pos_tags = nltk.pos_tag(word_tokenize(string)) # Get position tags\n",
    "    a=[wl.lemmatize(tag[0], get_wordnet_pos(tag[1])) for idx, tag in enumerate(word_pos_tags)] # Map the position tag and lemmatize the word/token\n",
    "    return \" \".join(a)\n",
    "def finalpreprocess(string):\n",
    "    return lemmatizer(stopword(preprocess(string)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T08:16:24.601492Z",
     "iopub.status.busy": "2022-07-22T08:16:24.601106Z",
     "iopub.status.idle": "2022-07-22T08:16:24.606891Z",
     "shell.execute_reply": "2022-07-22T08:16:24.605761Z",
     "shell.execute_reply.started": "2022-07-22T08:16:24.601462Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T08:16:24.609291Z",
     "iopub.status.busy": "2022-07-22T08:16:24.608679Z",
     "iopub.status.idle": "2022-07-22T08:16:29.733915Z",
     "shell.execute_reply": "2022-07-22T08:16:29.732955Z",
     "shell.execute_reply.started": "2022-07-22T08:16:24.609256Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T08:16:29.735589Z",
     "iopub.status.busy": "2022-07-22T08:16:29.735252Z",
     "iopub.status.idle": "2022-07-22T08:16:29.744876Z",
     "shell.execute_reply": "2022-07-22T08:16:29.743699Z",
     "shell.execute_reply.started": "2022-07-22T08:16:29.735556Z"
    }
   },
   "outputs": [],
   "source": [
    "init_token = tokenizer.cls_token\n",
    "eos_token = tokenizer.sep_token\n",
    "pad_token = tokenizer.pad_token\n",
    "unk_token = tokenizer.unk_token\n",
    "init_token_idx = tokenizer.cls_token_id\n",
    "eos_token_idx = tokenizer.sep_token_id\n",
    "pad_token_idx = tokenizer.pad_token_id\n",
    "unk_token_idx = tokenizer.unk_token_id\n",
    "print(init_token, eos_token, pad_token, unk_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T08:16:29.747443Z",
     "iopub.status.busy": "2022-07-22T08:16:29.746729Z",
     "iopub.status.idle": "2022-07-22T08:16:29.759337Z",
     "shell.execute_reply": "2022-07-22T08:16:29.758022Z",
     "shell.execute_reply.started": "2022-07-22T08:16:29.747407Z"
    }
   },
   "outputs": [],
   "source": [
    "max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
    "\n",
    "print(max_input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T08:16:29.761364Z",
     "iopub.status.busy": "2022-07-22T08:16:29.760986Z",
     "iopub.status.idle": "2022-07-22T08:16:29.768812Z",
     "shell.execute_reply": "2022-07-22T08:16:29.767817Z",
     "shell.execute_reply.started": "2022-07-22T08:16:29.761328Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_and_cut(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence) \n",
    "    tokens = tokens[:max_input_length-2]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T08:16:29.770833Z",
     "iopub.status.busy": "2022-07-22T08:16:29.770436Z",
     "iopub.status.idle": "2022-07-22T08:16:29.778212Z",
     "shell.execute_reply": "2022-07-22T08:16:29.776995Z",
     "shell.execute_reply.started": "2022-07-22T08:16:29.770801Z"
    }
   },
   "outputs": [],
   "source": [
    "TEXT = data.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = tokenize_and_cut,\n",
    "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                  init_token = init_token_idx,\n",
    "                  eos_token = eos_token_idx,\n",
    "                  pad_token = pad_token_idx,\n",
    "                  unk_token = unk_token_idx)\n",
    "LABEL = data.LabelField(dtype = torch.float,sequential=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T08:16:29.784374Z",
     "iopub.status.busy": "2022-07-22T08:16:29.783489Z",
     "iopub.status.idle": "2022-07-22T08:16:34.566012Z",
     "shell.execute_reply": "2022-07-22T08:16:34.565026Z",
     "shell.execute_reply.started": "2022-07-22T08:16:29.784343Z"
    }
   },
   "outputs": [],
   "source": [
    "train = data.TabularDataset('../input/proces-data/train_for_bert.csv', format='csv',skip_header=True,\n",
    "        fields=[('text',TEXT),('id',LABEL)])\n",
    "test = data.TabularDataset('../input/proces-data/test_for_bert.csv', format='csv',skip_header=True,\n",
    "        fields=[('text',TEXT),('id',LABEL)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T08:16:34.567803Z",
     "iopub.status.busy": "2022-07-22T08:16:34.567448Z",
     "iopub.status.idle": "2022-07-22T08:16:34.573898Z",
     "shell.execute_reply": "2022-07-22T08:16:34.572862Z",
     "shell.execute_reply.started": "2022-07-22T08:16:34.567766Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in test:\n",
    "    print(i.text)\n",
    "    print(tokenizer.convert_ids_to_tokens(list(i.text)))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T08:16:34.576023Z",
     "iopub.status.busy": "2022-07-22T08:16:34.575392Z",
     "iopub.status.idle": "2022-07-22T08:16:34.588551Z",
     "shell.execute_reply": "2022-07-22T08:16:34.587391Z",
     "shell.execute_reply.started": "2022-07-22T08:16:34.575987Z"
    }
   },
   "outputs": [],
   "source": [
    "# TEXT.build_vocab(train, vectors='glove.6B.100d')\n",
    "LABEL.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T08:16:34.591794Z",
     "iopub.status.busy": "2022-07-22T08:16:34.591411Z",
     "iopub.status.idle": "2022-07-22T08:16:34.598666Z",
     "shell.execute_reply": "2022-07-22T08:16:34.597527Z",
     "shell.execute_reply.started": "2022-07-22T08:16:34.591759Z"
    }
   },
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
    "    (train,test), \n",
    "    batch_size = 64,\n",
    "    shuffle=False,\n",
    "    sort_within_batch = True,\n",
    "    sort_key = lambda x: len(x.text),\n",
    "    device = device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T08:16:34.600506Z",
     "iopub.status.busy": "2022-07-22T08:16:34.600067Z",
     "iopub.status.idle": "2022-07-22T08:16:34.607579Z",
     "shell.execute_reply": "2022-07-22T08:16:34.606686Z",
     "shell.execute_reply.started": "2022-07-22T08:16:34.600471Z"
    }
   },
   "outputs": [],
   "source": [
    "# test1 = data.BucketIterator(\n",
    "#     test, \n",
    "#     batch_size = 1,\n",
    "#     shuffle=False,\n",
    "#     sort_within_batch = True,\n",
    "#     sort_key = lambda x: len(x.text),\n",
    "#     device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T08:16:34.610060Z",
     "iopub.status.busy": "2022-07-22T08:16:34.609168Z",
     "iopub.status.idle": "2022-07-22T08:16:38.092237Z",
     "shell.execute_reply": "2022-07-22T08:16:38.091298Z",
     "shell.execute_reply.started": "2022-07-22T08:16:34.610033Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "bert = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T08:16:38.094101Z",
     "iopub.status.busy": "2022-07-22T08:16:38.093764Z",
     "iopub.status.idle": "2022-07-22T08:16:38.105022Z",
     "shell.execute_reply": "2022-07-22T08:16:38.103915Z",
     "shell.execute_reply.started": "2022-07-22T08:16:38.094066Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class BERTGRUSentiment(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_dim,\n",
    "                 output_dim,\n",
    "                 n_layers,\n",
    "                 bidirectional,\n",
    "                 dropout):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.bert = bert\n",
    "        \n",
    "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
    "        \n",
    "        self.rnn = nn.GRU(embedding_dim,\n",
    "                          hidden_dim,\n",
    "                          num_layers = n_layers,\n",
    "                          bidirectional = bidirectional,\n",
    "                          batch_first = True,\n",
    "                          dropout = 0 if n_layers < 2 else dropout)\n",
    "        \n",
    "        self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        #text = [batch size, sent len]\n",
    "                \n",
    "        with torch.no_grad():\n",
    "            embedded = self.bert(text)[0]\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        _, hidden = self.rnn(embedded)\n",
    "        \n",
    "        #hidden = [n layers * n directions, batch size, emb dim]\n",
    "        \n",
    "        if self.rnn.bidirectional:\n",
    "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        else:\n",
    "            hidden = self.dropout(hidden[-1,:,:])\n",
    "                \n",
    "        #hidden = [batch size, hid dim]\n",
    "        \n",
    "        output = self.out(hidden)\n",
    "        \n",
    "        #output = [batch size, out dim]\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T08:16:38.119138Z",
     "iopub.status.busy": "2022-07-22T08:16:38.118857Z",
     "iopub.status.idle": "2022-07-22T08:16:38.131514Z",
     "shell.execute_reply": "2022-07-22T08:16:38.130427Z",
     "shell.execute_reply.started": "2022-07-22T08:16:38.119115Z"
    }
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "def calc_f1(preds,y):\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    return rounded_preds.tolist(),y.tolist()\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T08:16:38.133551Z",
     "iopub.status.busy": "2022-07-22T08:16:38.133072Z",
     "iopub.status.idle": "2022-07-22T08:16:38.141567Z",
     "shell.execute_reply": "2022-07-22T08:16:38.140353Z",
     "shell.execute_reply.started": "2022-07-22T08:16:38.133456Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.id)\n",
    "        acc = binary_accuracy(predictions, batch.id)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T08:58:52.125829Z",
     "iopub.status.busy": "2022-07-22T08:58:52.125449Z",
     "iopub.status.idle": "2022-07-22T08:58:52.135759Z",
     "shell.execute_reply": "2022-07-22T08:58:52.134770Z",
     "shell.execute_reply.started": "2022-07-22T08:58:52.125799Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    p_arr = []\n",
    "    r_arr = []\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.id)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.id)\n",
    "            a,b = calc_f1(predictions, batch.id)\n",
    "            p_arr.extend(a)\n",
    "            r_arr.extend(b)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "    print(classification_report(r_arr,p_arr,digits=4))\n",
    "    print('binary:', f1_score(r_arr, p_arr, average='binary'))\n",
    "    print('acc',accuracy_score(r_arr,p_arr))\n",
    "    print('recall',recall_score(r_arr,p_arr))\n",
    "    print('pre',precision_score(r_arr,p_arr))\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T08:16:38.159004Z",
     "iopub.status.busy": "2022-07-22T08:16:38.157949Z",
     "iopub.status.idle": "2022-07-22T08:16:38.323656Z",
     "shell.execute_reply": "2022-07-22T08:16:38.322770Z",
     "shell.execute_reply.started": "2022-07-22T08:16:38.158968Z"
    }
   },
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.2\n",
    "\n",
    "model = BERTGRUSentiment(bert,\n",
    "                         HIDDEN_DIM,\n",
    "                         OUTPUT_DIM,\n",
    "                         N_LAYERS,\n",
    "                         BIDIRECTIONAL,\n",
    "                         DROPOUT)\n",
    "for name, param in model.named_parameters():                \n",
    "    if name.startswith('bert'):\n",
    "        param.requires_grad = False\n",
    "# LEARNING_RATE = 0.001\n",
    "optimizer = optim.Adam(params =  model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-07-22T08:16:38.325129Z",
     "iopub.status.busy": "2022-07-22T08:16:38.324803Z",
     "iopub.status.idle": "2022-07-22T08:18:45.397603Z",
     "shell.execute_reply": "2022-07-22T08:18:45.395848Z",
     "shell.execute_reply.started": "2022-07-22T08:16:38.325096Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 20\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "#     if valid_loss < best_valid_loss:\n",
    "#         best_valid_loss = valid_loss\n",
    "#         torch.save(model.state_dict(), 'tut4-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T08:58:56.879766Z",
     "iopub.status.busy": "2022-07-22T08:58:56.879394Z",
     "iopub.status.idle": "2022-07-22T08:58:58.324591Z",
     "shell.execute_reply": "2022-07-22T08:58:58.323532Z",
     "shell.execute_reply.started": "2022-07-22T08:58:56.879734Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate(model, valid_iterator, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-22T08:18:46.844547Z",
     "iopub.status.idle": "2022-07-22T08:18:46.845258Z",
     "shell.execute_reply": "2022-07-22T08:18:46.844899Z",
     "shell.execute_reply.started": "2022-07-22T08:18:46.844875Z"
    }
   },
   "outputs": [],
   "source": [
    "Epoch: 09 | Epoch Time: 0m 6s\n",
    "\tTrain Loss: 0.180 | Train Acc: 93.81%\n",
    "\t Val. Loss: 0.269 |  Val. Acc: 89.04%\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.93      0.96      0.95       355\n",
    "         1.0       0.93      0.87      0.90       199\n",
    "\n",
    "    accuracy                           0.93       554\n",
    "   macro avg       0.93      0.92      0.92       554\n",
    "weighted avg       0.93      0.93      0.93       554\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-22T08:18:46.847087Z",
     "iopub.status.idle": "2022-07-22T08:18:46.849070Z",
     "shell.execute_reply": "2022-07-22T08:18:46.848831Z",
     "shell.execute_reply.started": "2022-07-22T08:18:46.848806Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_sentiment(model, tokenizer, sentence):\n",
    "    model.eval()\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    tokens = tokens[:max_input_length-2]\n",
    "    indexed = [init_token_idx] + tokenizer.convert_tokens_to_ids(tokens) + [eos_token_idx]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(0)\n",
    "    prediction = torch.round(torch.sigmoid(model(tensor)))\n",
    "#     prediction = torch.sigmoid(model(tensor))\n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
